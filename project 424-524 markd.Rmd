---
title: "Project 424/524 a"
author: "Nina Kerkebane"
date: "March 1, 2020"
output: html_document
---

#Loading packages 
```{r setup}
knitr::opts_chunk$set(echo = TRUE)
library(pacman)
p_load(dplyr, readr, janitor, ggplot2, caret, naniar, tidymodels, class)
```

#Merging datasets

```{r Merging datasets, warning=FALSE}
# importing by-year tuition data

t11 = read_csv("C:/Users/Nina/Documents/College Classes/Winter 2020/Econ/424-524-project/tui_11.csv")
t12 = read.csv("C:/Users/Nina/Documents/College Classes/Winter 2020/Econ/424-524-project/tui_12.csv")
t13 = read.csv("C:/Users/Nina/Documents/College Classes/Winter 2020/Econ/424-524-project/tui_13.csv")
t14 = read.csv("C:/Users/Nina/Documents/College Classes/Winter 2020/Econ/424-524-project/tui_14.csv")
t15 = read.csv("C:/Users/Nina/Documents/College Classes/Winter 2020/Econ/424-524-project/tui_15.csv")
t16 = read.csv("C:/Users/Nina/Documents/College Classes/Winter 2020/Econ/424-524-project/tui_16.csv")

# combining to make overall tuition df
tui_clean <- as.data.frame(rbind(t11, t12, t13, t14, t15, t16))

```

#Cleaning the data 

```{r data cleaning}

#checking for missing data 
#then replacing missing values with the median of each variable usinf preProcess function

gg_miss_var(tui_clean) # visual of the missing data 

tui_clean <- preProcess(
  x = tui_clean,
  method = c("medianImpute")
) %>% predict(tui_clean)

sum(is.na(tui_clean))


```
#Splitting the data into train and test

```{r Training/testing data}
# split data into test and training data  20% 80%--

set.seed(0726)
tui_clean_split <- initial_split(tui_clean, prop = 0.8)

```

#Training the models
```{r models}
split_train <- training(tui_clean_split)
split_test <- testing(tui_clean_split)

#train data using four different models-
##first model: logistic----------------------

model_glmnet = train(
  ft_ret_rate ~ .,
  data = training(tui_clean_split) %>% select(-c(a_unit_id, a_institution)),
  method = "glmnet",
  trControl = trainControl(method = "cv", number = 5),
  tuneGrid = expand.grid(
    alpha = seq(0, 1, 0.1),
    lambda = c(0.1, 0.01, 0.001, 0.0001, 0.00001)
  )
)
plot(model_glmnet)


##Second model : ridge---------------

lambdas = 10^seq(from = 5, to = -2, length = 100) #create lambdas to pick from

tui_train_matrix <- as.matrix(training(tui_clean_split)[,3:23])
#transform dataframe into matrix to use lasso/ridge and remove id and name of institution 

model_ridge = train(
  ft_ret_rate ~ .,
  data = tui_train_matrix ,
  method = "glmnet",
  trControl = trainControl(method = "cv", number = 5),
  tuneGrid = expand.grid(
    alpha = 0,
    lambda = lambdas
  ))
plot(model_ridge)


##Third model: lasso ---------------------
model_lasso = train(
  ft_ret_rate ~ .,
  data = tui_train_matrix ,
  method = "glmnet",
  trControl = trainControl(method = "cv", number = 5),
  tuneGrid = expand.grid(
    alpha = 1,
    lambda = lambdas
  ))
plot(model_lasso)

#Fourth Model:KNN          -----------------------


#model_knn <- train(  ft_ret_rate ~ .,  data = split_train,        method = "knn", 
 #        trControl = trainControl("cv", number = 5),
  #       preProcess = c("center","scale"),
   #    tuneLength = 5)

model_knn <- train(
  ft_ret_rate ~., 
  data = split_train[,3:23], 
  method = "knn",
  trControl = trainControl("cv", number = 5),
  preProcess = c("center","scale"),
  tuneLength = 5
  )
model_knn
plot(model_knn)

```


#Testing the models within the test dataset and comparing performance

```{r Testing the models}
#Test Test  performance with the held out data.
#need to find a way to estimate the accuracy of the prediction 
split_test$predict_glmnet <- predict(model_glmnet, newdata = split_test)
split_test$predict_lasso <- predict(model_lasso, newdata = split_test)
split_test$predict_ridge <- predict(model_ridge, newdata = split_test)
split_test$predict_knn <- predict(model_knn, newdata = split_test)



```

